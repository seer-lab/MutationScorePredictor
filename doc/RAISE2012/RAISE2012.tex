\documentclass[10pt,conference,compsocconf]{IEEEtran}


\usepackage[table]{xcolor}
\usepackage{cite}
\usepackage{url}
\usepackage[pdftex]{graphicx}
\usepackage{pifont}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{balance}
\usepackage{pgfplots}


\clubpenalty = 10000
\widowpenalty = 10000
\displaywidowpenalty = 10000


\begin{document}


\title{Predicting Mutation Score Using Source Code\\and Test Suite Metrics}


\author{\IEEEauthorblockN{Kevin Jalbert, Jeremy S. Bradbury}
\IEEEauthorblockA{Software Quality Research Group\\
University of Ontario Institute of Technology\\
Oshawa, Ontario, Canada\\
\{kevin.jalbert, jeremy.bradbury\}@uoit.ca}}


\maketitle


\begin{abstract}
Mutation testing has traditionally been used to evaluate the effectiveness of test suites and provide confidence in the testing process. Mutation testing involves the creation of many versions of a program each with a single syntactic fault. A test suite is evaluated against these program versions (mutants) in order to determine the percentage of mutants a test suite is able to identify (mutation score). A major drawback of mutation testing is that even a small program may yield thousands of mutants and can potentially make the process cost prohibitive. To improve the performance and reduce the cost of mutation testing, we propose a machine learning approach to predict mutation score based on a combination of source code and test suite metrics.
\end{abstract}


\IEEEpeerreviewmaketitle


\section{Introduction}
\label{sec:introduction}
Mutation testing has traditionally been used as a coverage technique to evaluate the effectiveness of test suites and provide confidence in the testing process~\cite{DLS78, OAL06, JH10}. For over 30 years, mutation testing has been applied to software written in programming languages including C~\cite{DM96, JH08}, Fortran~\cite{KO91} and Java~\cite{MKO02, BCD06}. Furthermore, mutation testing has also been applied to non-programming artifacts such as formal specification languages~\cite{ABM98} and spreadsheets~\cite{AE09}.

Mutation testing uses a set of \emph{mutation operators} to generate faulty versions of a program called \emph{mutants}. Mutation operators are created based on an existing fault taxonomy and each operator usually corresponds to a specific type of fault. A mutant is identical to the original program except that it contains a single mutation -- ``\emph{a single syntactic change that is made to a program statement.}''~\cite{KO91}. A test suite is evaluated against a set of mutants to determine the \emph{mutation score}. The mutation score is defined as the percentage of non-equivalent mutants that are detected (\emph{killed}) by a test suite. The better a test suite, the more mutants will be killed and thus the higher the mutation score.

A major drawback of mutation testing is that even a small program may yield hundreds or thousands of mutants -- potentially making the process cost prohibitive in comparison to other coverage metrics such as statement or branch coverage. Three approaches have been proposed in the literature to improve mutation testing performance and scalability~\cite{OU00}:

\begin{enumerate}
  \item \textbf{``Do fewer'' approach:} this category of optimizations aim to decrease the computational cost of mutation testing by reducing the number of mutants that a test suite is evaluated against. The most popular example from this category is selective mutation -- the use of a subset of mutation operators that have been empirically shown to be as effective as using an entire set of operators~\cite{OLR+96}. Another example of a ``do fewer'' approach is to randomly sample mutants~\cite{Won93}.

  \item \textbf{``Do smarter'' approach:} this category of optimizations aim to decrease the cost of mutation testing by improving the actual mutation testing technique. For example, weak mutation \emph{``...is an approximation technique that compares the internal states of mutant and original program immediately after execution of the mutated portion of the code (instead of comparing the program output)''}~\cite{OU00}.

  \item \textbf{``Do faster'' approach:} this category of optimizations aim to reduce the cost of mutation testing by focusing on performance. For example, one ``do faster'' approach improves compilation time using schema-based mutation -- \emph{``...encodes all mutations into one source level program...''}~\cite{OU00}.
\end{enumerate}

As an alternative to the above approaches, we propose a ``do fewer and smarter'' technique for mutation testing at the unit level.  When mutation testing is used for the creation or improvement of a test suite,  the test suite will often have to be applied to the mutants in an iterative fashion as tests are added, removed and modified. Furthermore, the effects on the mutation score after each iteration have to be observed. We propose to replace at least some of the mutation testing of intermediate tests with mutation score prediction and thus decrease the number of mutants that have to be evaluated using a test suite. Our proposed approach uses machine learning to predict the mutation score based on a combination of source code and test suite metrics of the code unit under test.

Next, in Section~\ref{sec:background} we describe the machine learning technique, the mutation testing tool and the metrics gathering tools used in our research. In Section~\ref{sec:approach} we describe our overall approach to mutant score prediction. We also discuss the integration of the tools described in Section~\ref{sec:background}, into our approach. In Section~\ref{sec:case_study} we apply our approach to an open source project and discuss the effectiveness of our prediction based on this preliminary evaluation. Finally, in Sections~\ref{sec:related_work}~\&~\ref{sec:conclusions_future_work} we discuss related work, conclusions, and future work.


\section{Background}
\label{sec:background}
In this section we describe the background techniques and tools used in our research. In particular, we discuss LIBSVM (a support vector machine library), Javalanche (a mutation testing tool), the Eclipse Metrics Plugin (used for gathering source code metrics), and EMMA (used for acquiring test suite metrics). All tools were selected based on three criteria: (1) ability to execute command-line using a script, (2) ability to export output reports and (3) ability to fulfill the needs of our research.


\subsection{LIBSVM -- a library for support vector machines}
\label{subsec:libsvm}
A support vector machine (SVM) is an example of a linear discrimination machine learning technique and assumes that ``...\emph{instances of a class are linearly separable from instances of other classes}''~\cite{ALP04}. A SVM is capable of learning how a set of features inform the classification of a data item. It can also be trained on known data items (in which the features and category are present), and then used to predict the category of  unknown data items (in which only the features are present).

Traditionally, SVMs have been used for two-group classification problems~\cite{CV95} but have also been generalized to \emph{n}-group classification problems. In a two-group classification problem an optimal separating hyperplane is identified that divides the set of data into two groups based on a set of support vectors (i.e., features). In other words, the goal is to maximize the distance from the closest data points on both sides of the hyperplane to the hyperplane itself~\cite{ALP04}.

In our research we use LIBSVM (version 3.11), a SVM library capable of solving \emph{n}-group classification problems~\cite{CL11}.


\subsection{Javalanche -- a mutation testing tool for Java}
\label{subsec:javalanche}
Mutation testing has previously been described in Section~\ref{sec:introduction}. In our research we use Javalanche (version 0.4), a mutation testing tool for Java~\cite{SZ09} that applies a subset of the method-level mutation operators. Method-level operators are the most common set of mutation operators applied to procedural programming languages and each method-level mutation defines a syntactic change to an operator, operand or statement in a program. Javalanche uses a subset of the method-level mutation operators (replace constant, negate jump, arithmetic replace, remove call, replace variable, absolute value, unary operator). These selected operators provide a close approximation of the effectiveness of using the entire set of method-level operators at a reduced cost~\cite{OLR+96}.

We chose Javalanche for our research because it is customizable and extensible, therefore allowing us to modify Javalanche to calculate unit mutation scores and output a richer set of results. We plan to further take advantage of Javalanche's extensibility in the future by adding object-oriented mutation operators. Other benefits of Javalanche include: full integration with JUnit and the use of mutation schemas to improve performance.

\subsection{Eclipse Metrics Plugin -- a source code metrics tool}
\label{subsec:Metrics}
Source code metrics give insight into various aspects of the source code including it's complexity, size, coupling, cohesion as well as object-oriented attributes~\cite{SCE05,McCa76,Kan02,HWY09,Hend95,SRD12}. In our research, we use the Eclipse Metrics Plugin (version 1.3.8.20100730-001) to acquire source code metrics of the method- and class-level code unit under test~\cite{Metrics}. We selected this tool as it provides a comprehensive set of metrics for Java programs (see feature sets \ding{172}~\&~\ding{174} from Table~\ref{tab:metrics}).

\begin{table}[!t]
  \caption{The set of metrics used in our research. Organized by feature set (\ding{172}: Source Code Metrics, \ding{173}: Coverage Metrics, \ding{174}: Accumulated Source Code Metrics, \ding{175}: Accumulated Test Case Metrics)}
  \centering
  \rowcolors{2}{gray!30}{gray!20}
  \begin{tabular}{|l|l|l|l|}
    \hline
    \rowcolor[RGB]{169,196,223}
    \textbf{Metrics} & \textbf{Description} & \textbf{Scope} & \textbf{Set} \\

    % Set 1: Source Code Metrics
    \hline MLOC & Method lines of code & Method & \ding{172} \\
    \hline NBD & Nested block depth & Method & \ding{172} \\
    \hline VG & McCabe cyclomatic complexity & Method & \ding{172} \\
    \hline PAR & Number of parameters & Method & \ding{172} \\
    \hline NORM & Number of overridden methods & Class & \ding{172} \\
    \hline NOF & Number of attributes & Class & \ding{172} \\
    \hline NSC & Number of children & Class & \ding{172} \\
    \hline DIT & Depth of inheritance tree & Class & \ding{172} \\
    \hline LCOM & Lack of cohesion of methods & Class & \ding{172} \\
    \hline NSM & Number of static methods & Class & \ding{172} \\
    \hline NOM & Number of methods & Class & \ding{172} \\
    \hline SIX & Specialization index & Class & \ding{172} \\
    \hline WMC & Weighted method per class & Class & \ding{172} \\
    \hline NSF & Number of static attributes & Class & \ding{172} \\

    % Set 2: Coverage Metrics
    \hline BCOV & Basic blocks covered in code unit & Class & \ding{173} \\
    \hline BTOT & Total basic blocks for code unit & Class & \ding{173} \\

    % Set 3: Accumulated Source Code Metrics
    \hline SMLOC & Sum MLOC of methods & Class & \ding{174} \\
    \hline SNBD & Sum NBD of methods & Class & \ding{174} \\
    \hline SVG & Sum VG of methods & Class & \ding{174} \\
    \hline SPAR & Sum PAR of methods & Class & \ding{174} \\
    \hline AMLOC & Average MLOC of methods & Class & \ding{174} \\
    \hline ANBD & Average NBD of methods & Class & \ding{174} \\
    \hline AVG & Average VG of methods & Class & \ding{174} \\
    \hline APAR & Average PAR of methods & Class & \ding{174} \\

    % Set 4: Accumulated Test Case Metrics
    \hline STMLOC & Sum MLOC of test methods & Class/Method & \ding{175} \\
    \hline STNBD & Sum NBD of test methods & Class/Method & \ding{175} \\
    \hline STVG & Sum VG of test methods & Class/Method & \ding{175} \\
    \hline STPAR & Sum PAR of test methods & Class/Method & \ding{175} \\
    \hline ATMLOC & Average MLOC of test methods & Class/Method & \ding{175} \\
    \hline ATNBD & Average NBD of test methods & Class/Method & \ding{175} \\
    \hline ATVG & Average VG of test methods & Class/Method & \ding{175} \\
    \hline ATPAR & Average PAR of test methods & Class/Method & \ding{175} \\
    \hline
  \end{tabular}
  \label{tab:metrics}
\end{table}


\subsection{EMMA -- a test suite coverage tool}
\label{subsec:emma}
Test suite metrics can be gathered using similar technique to those used in the gathering of source code metrics. In fact, since we focus on JUnit test cases (which are Java classes) we can actually use the Eclipse Metrics Plugin to gather some of the test suite metrics (see feature set \ding{175} from Table~\ref{tab:metrics}). To gather other test suite metrics we use EMMA (version 2.0.5312) which is capable of determining the statement and basic block coverage of a test suite~\cite{EMMA}. We use EMMA to acquire metrics for feature set \ding{173} from Table~\ref{tab:metrics}.


\section{Approach}
\label{sec:approach}
We now describe our SVM approach to determining the mutation score of a unit under test based on source code and test suite metrics. In Section~\ref{subsec:training} we outline the process for collecting our initial data and training the SVM (see Figure~\ref{fig:process}) and in Section~\ref{subsec:prediction} we describe how to use the SVM for prediction.

\begin{figure}[!t]
  \centering
  \includegraphics[width=8.5cm]{figures/process.pdf}
  \caption{Our SVM training process.}
  \label{fig:process}
\end{figure}


\subsection{Training}
\label{subsec:training}
Our training process requires as input a set of units of code and for each code unit a corresponding set of unit test cases. Both the code units under test and test cases (i.e., JUnit tests) are Java source files.

The first step of our process is to collect the two types of data required to train the SVM:

\begin{itemize}
  \item \textbf{Category Data:} Javalanche is used to generate the mutants of all code units in the project under test and to perform the mutation testing by executing the required tests for each mutant. It should be noted that currently our Javalanche configuration does not exclude equivalent mutants from the analysis. For our research, we added a new analyzer component to Javalanche that outputs an intermediate text file of mutation scores of the covered units (methods and classes).

  \item \textbf{Feature Data:} The feature data is comprised of the source code and test suite metrics (see Table~\ref{tab:metrics} for feature sets referenced in the following text). By using the Eclipse Metric Plugin we collect source code metrics (sets \ding{172}~\&~\ding{174}) for both method- and class-level code units. We also collect the test suite metrics (set \ding{175}) of each unit's test cases using the Eclipse Metric Plugin. Test suite coverage metrics (set \ding{173}) are obtained using the EMMA tool.
\end{itemize}

Next, we create a .libsvm file containing the category and feature data from the database. Instead of predicting a specific mutation score percentage, we categorize all mutation scores as \textit{low, medium, high} which reduces the mutation score prediction to a three-group classification problem. The ranges of values in each category are determined based on the distribution of the mutation scores in our training data (further explained in Section~\ref{subsec:results}). Finally, the .libsvm file is passed into LIBSVM to complete the training process.


\subsection{Prediction}
\label{subsec:prediction}
Once we have trained the SVM, we can then use the SVM for prediction. We can predict the mutation score category of an unknown unit of code by first determining the source code and test suite metrics. The metrics (i.e., features) are passed into the SVM which will then assign a category of \textit{low, medium, high} for the mutation score.  Currently, our approach only predicts mutation scores within a project. That is, the training and prediction data both come from the same project repository.


\section{Case Study: JGAP}
\label{sec:case_study}
\begin{table}[!t]
  \caption{The amount of classes, methods, lines of code (LOC), and JUnit test cases in the JGAP repository}
  \centering
  \rowcolors{2}{gray!30}{gray!20}
  \begin{tabular}{|l|r|r|}
    \hline
    \rowcolor[RGB]{169,196,223}
    \textbf{JGAP Source Artifacts} & \textbf{\# in Source} & \textbf{\# in Test} \\
    \hline Classes & 415 & 180 \\
    \hline Methods & 3017 & 1626 \\
    \hline LOC & 28975 & 19556 \\
    \hline JUnit Test Cases & -- & 1412\footnotemark[1] \\
    \hline
  \end{tabular}
  \label{tab:jgap_source_stats}
\end{table}

A preliminary evaluation of our mutation score predictor was preformed on JGAP (version 3.6.1), an open source genetic algorithm and genetic programming framework for Java, which was selected due to its comprehensive and mature JUnit test suite~\cite{JGAP}. Basic source code metrics for JGAP are provided in Table~\ref{tab:jgap_source_stats}. JGAP contains 1387\footnote{JGAP has 1412 JUnit test cases in total, however 25 of the tests caused errors in the Javalanche tool and were removed.} usable JUnit test cases. For JGAP, Javalanche generated 32031 mutants using the method-level mutation operators (see Section~\ref{subsec:javalanche}) of which only 18378 were actually covered by JGAP's test suite. We only considered the set of covered mutations in our approach as the mutations not covered contained no associated test cases. Considering only the covered mutants, JGAP's test suite killed 13698 mutants in 688 minutes and 43 seconds\footnote{Results from Javalanche on Intel Core i7-870 processor @ 2.93 GHz (with no parallel task execution).} resulting in an overall mutation score of 74.53\%.


\subsection{Results}
\label{subsec:results}
We gathered 695 method-level data points and 127 class-level data points from JGAP. We first decided to view the distribution of JGAP's mutation scores (see Figure~\ref{fig:mutation_distributions_class}~\&~\ref{fig:mutation_distributions_method}). It is clearly obvious that the distribution for both classes and methods are more heavily dense for high mutation scores. As discussed in Section~\ref{subsec:training} we categorize the collected data into three groups of \textit{low, medium, high} mutation scores. Ideally we would have liked to have sufficient data coverage, such that we can use simple categories such as 0\%--33\% (\textit{low}), 33\%-66\% (\textit{medium)} and 66\%-100\% (\textit{high}). Based on the distribution of mutation scores in JGAP we instead decided to categorize our data such that one third of our data fall into each category (see Table~\ref{tab:results_details}).

\begin{figure}[!t]
  \centering
  \begin{tikzpicture}
  \begin{axis}[
      xtick={0, 25, 50, 75, 100},
      ytick={0, 2, 4, 6, 8, 10, 12, 14, 16},
      bar width=1,
      ymajorgrids=true,
      xlabel=Mutation Score (\%),
      ylabel=\# of Classes,
      width=8.5cm,
      height=8cm]
      \addplot[ybar,fill=black] coordinates {
(0, 7) (1, 0) (2, 0) (3, 0) (4, 0) (5, 0) (6, 0) (7, 1) (8, 0) (9, 0) (10, 0) (11, 0) (12, 0) (13, 0) (14, 0) (15, 0) (16, 0) (17, 0) (18, 1) (19, 1) (20, 0) (21, 0) (22, 0) (23, 0) (24, 0) (25, 0) (26, 0) (27, 0) (28, 0) (29, 1) (30, 1) (31, 0) (32, 0) (33, 3) (34, 0) (35, 0) (36, 1) (37, 0) (38, 0) (39, 0) (40, 0) (41, 1) (42, 2) (43, 0) (44, 0) (45, 0) (46, 2) (47, 1) (48, 1) (49, 5) (50, 0) (51, 1) (52, 3) (53, 1) (54, 0) (55, 0) (56, 1) (57, 2) (58, 2) (59, 1) (60, 0) (61, 1) (62, 3) (63, 1) (64, 3) (65, 0) (66, 1) (67, 2) (68, 2) (69, 0) (70, 0) (71, 4) (72, 5) (73, 0) (74, 4) (75, 5) (76, 3) (77, 1) (78, 2) (79, 3) (80, 0) (81, 2) (82, 3) (83, 2) (84, 2) (85, 1) (86, 5) (87, 4) (88, 2) (89, 1) (90, 1) (91, 4) (92, 3) (93, 0) (94, 1) (95, 0) (96, 1) (97, 0) (98, 1) (99, 15)
      };
  \end{axis}
  \end{tikzpicture}
  \caption{The mutation score distribution of JGAP's classes that can be used for training.}
  \label{fig:mutation_distributions_class}
\end{figure}

\begin{figure}[!t]
  \centering
  \begin{tikzpicture}
  \begin{axis}[
      xtick={0, 25, 50, 75, 100},
      ytick={0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220},
      bar width=1,
      ymajorgrids=true,
      xlabel=Mutation Score (\%),
      ylabel=\# of Methods,
      width=8.5cm,
      height=8cm]
      \addplot[ybar,fill=black] coordinates {
(0, 42) (1, 0) (2, 0) (3, 0) (4, 0) (5, 0) (6, 0) (7, 0) (8, 1) (9, 0) (10, 0) (11, 1) (12, 0) (13, 0) (14, 0) (15, 0) (16, 0) (17, 0) (18, 2) (19, 4) (20, 1) (21, 0) (22, 1) (23, 0) (24, 6) (25, 0) (26, 1) (27, 2) (28, 1) (29, 1) (30, 1) (31, 1) (32, 0) (33, 11) (34, 1) (35, 0) (36, 3) (37, 1) (38, 1) (39, 12) (40, 1) (41, 1) (42, 6) (43, 6) (44, 2) (45, 1) (46, 2) (47, 1) (48, 1) (49, 40) (50, 0) (51, 4) (52, 4) (53, 1) (54, 2) (55, 3) (56, 1) (57, 5) (58, 1) (59, 22) (60, 2) (61, 3) (62, 4) (63, 1) (64, 7) (65, 4) (66, 17) (67, 4) (68, 5) (69, 6) (70, 10) (71, 5) (72, 7) (73, 5) (74, 21) (75, 3) (76, 6) (77, 9) (78, 6) (79, 30) (80, 6) (81, 10) (82, 12) (83, 23) (84, 8) (85, 6) (86, 14) (87, 14) (88, 4) (89, 10) (90, 3) (91, 5) (92, 5) (93, 3) (94, 2) (95, 0) (96, 0) (97, 1) (98, 2) (99, 214)
      };
  \end{axis}
  \end{tikzpicture}
  \caption{The mutation score distribution of JGAP's methods that can be used for training.}
  \label{fig:mutation_distributions_method}
\end{figure}

\begin{table}[!b]
  \caption{The mutation score ranges that equally partition the datasets into three mutation score categories.}
  \centering
  \rowcolors{2}{gray!30}{gray!20}
  \begin{tabular}{|l|r|r|}
    \hline
    \rowcolor[RGB]{169,196,223}
    \textbf{Category} & \textbf{Class Mutation Score} & \textbf{Method Mutation Score} \\
    \hline low & 0.00\% -- 62.75\% & 0.00\% -- 66.66\% \\
    \hline medium & 62.75\% -- 83.25\% & 66.66\% -- 90.90\% \\
    \hline high & 83.25\% -- 100.00\% & 90.90\% -- 100.00\% \\
    \hline
  \end{tabular}
  \label{tab:results_details}
\end{table}

Due to the small amount of data acquired from this experiment we decided to evaluate our results by performing a 10-fold cross-validation of our datasets. Effectively, this divides our dataset into \emph{10} equal-sized partitions and the SVM trains on $\emph{9}$ sets and predicts on the last. This process is repeated \emph{10} times where a different partition is selected for prediction each time. Finally all the individual prediction accuracies are tallied and averaged for a cross-validation accuracy of \emph{10}-folds. Our achieved cross-validation accuracy of JGAP (with all features from Table~\ref{tab:metrics}) was 58.27\% for class mutation scores and 54.82\% for method mutation scores. Figure~\ref{fig:confusion_matrix} illustrates a confusion matrix of the predicted values created from the SVM data for our three categories. It is also worth mentioning that our achieved accuracy outperforms random (which has an accuracy of 33.33\% given our category distributions) by 24.94\% for classes and 21.49\% for methods.

\begin{figure}[!t]
  \small
  \begin{tikzpicture}[
  box/.style={draw,rectangle,minimum size=0.5cm,text width=1.25cm,align=center}]
    \matrix (confusion_matrix) {
      \node (actual_low_prediction_low)
      [box,
        label=left:\(\mathbf{L'}\),
        label=above:\(\mathbf{L}\)
      ] {29, 108};
      &
      \node (actual_low_prediction_medium)
      [box,
        label=above:\(\mathbf{M}\)
      ] {7, 54};
      &
      \node (actual_low_prediction_high)
      [box,
        label=above:\(\mathbf{H}\)
      ] {7, 74};
      \\
      \node (actual_medium_prediction_low)
      [box,
        label=left:\(\mathbf{M'}\)
      ] {11, 43};
      &
      \node (actual_medium_prediction_medium)
      [box] {20, 112};
      &
      \node (actual_medium_prediction_high)
      [box] {11, 72};
      \\
      \node (actual_high_prediction_low)
      [box,
        label=left:\(\mathbf{H'}\)
      ] {8, 31};
      &
      \node (actual_high_prediction_medium)
      [box] {9, 40};
      &
      \node (actual_high_prediction_high)
      [box] {25, 161};
      \\
    };
    \node [left=-.1cm of confusion_matrix,text width=1.5cm,align=right] {\textbf{Actual \\ Value}};
    \node [above=-.1cm of confusion_matrix] {\textbf{Prediction Value}};
  \end{tikzpicture}
  \caption{Confusion matrix for (class, method) mutation score prediction on JGAP using all feature sets from Table~\ref{tab:metrics}. The first value in each cell represents the class value while the second represents the method value. \(\mathbf{L}\) = Low, \(\mathbf{M}\) = Medium and \(\mathbf{H}\) = High.}
  \label{fig:confusion_matrix}
\end{figure}

We also conducted the cross-validation using subsets of our feature set and found that the combination of both source code and test suite features slightly improves the prediction accuracy (see Table~\ref{tab:subset_accuracy}).

\begin{table}[!t]
  \caption{The cross validation (10-folds) accuracy of each feature subset (see  Table~\ref{tab:metrics}) and all of four feature subsets combined.}
  \centering
  \rowcolors{2}{gray!30}{gray!20}
  \begin{tabular}{|c|r|r|}
    \hline
    \rowcolor[RGB]{169,196,223}
    \textbf{Set} & \textbf{Class Accuracy} & \textbf{Method Accuracy} \\
    \hline \ding{172} & 53.54\% & 48.77\% \\
    \hline \ding{173} & 49.61\% & 47.63\% \\
    \hline \ding{174} & 45.67\% & 49.78\% \\
    \hline \ding{175} & 54.33\% & 33.96\% \\
    \hline\ \textbf{\ding{172} \ding{173} \ding{174} \ding{175}} & \textbf{58.27\%} & \textbf{54.82\%} \\
    \hline
  \end{tabular}
  \label{tab:subset_accuracy}
\end{table}


\section{Related Work}
\label{sec:related_work}
The use of software metrics to locate faults in source code has been well researched. For example, Koru et al. utilized static software measure along with defect data at the class level to predict bugs using machine learning~\cite{KL05}. Similarly, Gyimothy et al. used object-oriented metrics with logistic regression and machine learning techniques to identify faulty classes in open source software~\cite{GFS05}. Finally, design level metrics were used with a linear prediction model to determine the estimated maintainability and error prone modules of large software systems~\cite{MKPS00}. Our work is unique in comparison to these previous works since we not only use source code metrics but we also use test suite metrics to enhance our predication capabilities.


\section{Conclusions \& Future Work}
\label{sec:conclusions_future_work}
Our technique for predicting mutation score using source code and test suite metrics outperforms random with an achieved accuracy of 58.27\% and 54.82\% with the JGAP data, for classes and methods respectively. These results have not been optimized and we believe that with further enhancements and a more tailored feature set we may be able to increase the prediction accuracy.

Despite the promising initial results there is an obvious threat to external validity since we have applied our predictive technique to a single open source project -- JGAP. Additionally, we performed training and prediction from the same project. As stated by Kitchenham and Mendes \textit{``It is invalid to select one or two datasets to `prove' the validity of a new technique because we cannot be sure that, of the many published datasets, those chosen are the only ones that favour the new technique''}~\cite{KM09}. Thus, we plan to evaluate more open source projects using our prediction technique to better assess the prediction accuracy. With more data we plan to investigate whether cross-project models are valid for mutation score prediction. We would also like to consider projects with more varied mutation scores to explore the variation in prediction accuracy between strong and weak test suites. A final area of future work is to expand the set of mutation operators used to include object oriented and concurrency operators.


\balance


\bibliographystyle{IEEEtran}
\bibliography{references}


\end{document}
